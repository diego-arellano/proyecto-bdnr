* PROYECTO-BDNR

Para este proyecto se utilizó la API de Star Wars gratuita llamada SWAPI, en la cual se almacena la información de personajes, planetas, naves, vehiculos, peliculas, especies de las primeras 7 películas, sí... involucra también a /The Force Awakens/. Nuestra intención fue utilizar esto debido a su facilidad de conexiones entre los personajes con las películas y objetos en los que aparecen o utilizan duranta las películas. 

*** [[https://swapi.py4e.com/documentation][Api utilizada]]

<link> https://ugeek.github.io/blog/post/2020-05-27-copiar-directorios-o-archivos-de-un-docker-a-local-o-viceversa.html


Agregué al script de conv_csv la siguiente instrucción dentro de cada for: 
docker cp ./$col.csv monetdb:/swapi_csv
Para después poder ejecutar dentro de monet las siguientes instrucciones:
Crear la tabla necesaria para cada una de las tablas 
copy offset 2 into people from '/swapi_csv/people.csv' on client using delimiters ',',E'\n',E'\"' null as ' ';

Nota: es importante checar la parte de los delimitadores todavía, porque las comas dentro de los arreglos están ocasionando serios problemas para copiar el csv a monet

Agregué los comandos necesarios para crear la base de datos en neo4j 

** Mongo 

#+begin_src shell
docker stop mongo
docker rm mongo

export DATA_DIR=`pwd`/data
echo $DATA_DIR
export EX_DIR=`pwd`/mongodb-sample-dataset
echo $EX_DIR
mkdir -p $DATA_DIR
docker run -p 27017:27017 \
       -v $DATA_DIR:/data/db \
       -v $EX_DIR:/mongodb-sample-dataset \
       --name mongo \
       -d mongo
#+end_src


Dentro de Python ejecutar las siguientes sentencias
       - A través de las cuales conectamos mongo con python y creamos las distintas colecciones existentes en mongo, dado que no existe un extract all o algo parecido *nota: la documentación dice que sí se puede a través de https://swapi.py4e.com/api/table/*, pero ¡esto es falso! Solo regresa los primeros 10, por lo tanto tuvimos que extraer todo lo posible iterando
       - Nueva sorpresa: la API no está completa, hay indices de URL que no contienen información y devuelven un error 404 :'( 
       Solución: la iteración se realiza por un while hasta el punto en que se han extraido todos los datos que la api reporta que existen, y el contador no aumenta salvo en el caso de que la respuesta no sea 404. Se apendea en una lista y se utiliza la función insert_many
       
#+begin_src py
import requests
from pymongo import MongoClient

client = MongoClient("mongodb://localhost:27017/")
my_db = client["swapi"]
list=["starships", "vehicles", "species", "films", "planets", "people"]

for table in list:
    collection = my_db[table]
    url = "https://swapi.py4e.com/api/"+table+"/"
    i = 1
    j = 1
    request = requests.get(url)
    response = request.json()
    limite = response["count"]
    print(limite)
    res = []

    while j <= limite:
        url_i = url + str(i)
        req = requests.get(url_i)
        if req.status_code != 404:
            resp = req.json()
            res.append(resp)
            print(j)
            j+=1
        i+=1
    print("fin de tabla"+table)
    collection.insert_many(res)
#+end_src

*** Queries Mongo:
       - Primer query, utilizado para extraer la información de mongo y enviarla a monet: practicamente se desglosan los arreglos existentes dentro de cada uno de los fields del json, pero que considere los casos vacíos y nulos
       #+begin_src js
       db.people.aggregate([{$unwind:{path:"$films",preserveNullAndEmptyArrays: true}},{$unwind:{path:"$species",preserveNullAndEmptyArrays: true}},{$unwind:{path:"$vehicles",preserveNullAndEmptyArrays: true}},{$unwind:{path:"$starships",preserveNullAndEmptyArrays: true}},{$project:{_id:0}},{$out:"people_monet"}])
       #+end_src
       - Segundo query:
       #+begin_src js
              
       #+end_src
       - Tercer query:
       #+begin_src js
              
       #+end_src
              
** Monetdb

*** Queries Monetdb


** Neo4j

*** Queries Neo:

